import asyncio,socket
from urllib.parse import urlparse
from  concurrent.futures import ThreadPoolExecutor

def get_url(url):
    newL = urlparse(url)
    path = newL.path
    host = newL.netloc
    print(host,path)
    if path=="":
        path = "/"
    exec = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
    exec.connect((host,80))

    # exec.send("GET / HTTP/1.1\r\nHost:{}\r\nConnection:close\r\n\r\n".format(host).encode("utf8"))
    exec.send("GET {} HTTP/1.1\r\nHost:{}\r\nConnection:close\r\n\r\n".format(path,host).encode("utf8"))
    data = b''
    while True:
        d = exec.recv(1024)
        if d:
            data += d
        else:
            break
    print(data.decode("utf8"))

if __name__=="__main__":
    loop = asyncio.get_event_loop()
    execute = ThreadPoolExecutor()
    tasks = []
    for _ in range(10):
        #将同步耗时放到进程池里面处理
        task = loop.run_in_executor(execute,get_url,"http://www.baidu.com")
        tasks.append(task)
    loop.run_until_complete(asyncio.wait(tasks))
